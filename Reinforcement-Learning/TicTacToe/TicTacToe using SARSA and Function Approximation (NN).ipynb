{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BaseAgent import BaseAgent\n",
    "from BaseEnvironment import BaseEnvironment\n",
    "from RLGlue import RLGlue\n",
    "from Softmax import softmax\n",
    "from Adam import Adam\n",
    "from SimpleNN import SimpleNN\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeEvnironment(BaseEnvironment):\n",
    "    def env_init(self, env_info={}):\n",
    "        pass\n",
    "    \n",
    "    def env_start(self):\n",
    "        self.terminal = False\n",
    "        self.board = np.zeros((3, 3))\n",
    "        self.reward_obs_term = (0, self.board, False)\n",
    "        return self.board.copy().reshape(1,-1), self.get_mask()\n",
    "    \n",
    "    def env_step(self, agent_num, index):\n",
    "        if self.terminal:\n",
    "            print(\"Environment in terminal state, please restart.\")\n",
    "        \n",
    "        row, col = self.transform_index(index)\n",
    "        self.board[row, col] = agent_num\n",
    "        \n",
    "        if self.check_won(agent_num):\n",
    "            reward = 10\n",
    "            self.terminal = True\n",
    "        elif self.check_tie():\n",
    "            reward = 0\n",
    "            self.terminal = True\n",
    "        else:\n",
    "            reward = -1\n",
    "            \n",
    "        self.reward_obs_term_mask = (reward, self.board.copy().reshape(1,-1), self.terminal, self.get_mask())\n",
    "        return self.reward_obs_term_mask\n",
    "    \n",
    "    def check_tie(self):\n",
    "        return (self.board == 0).sum() == 0\n",
    "    \n",
    "    def check_won(self, agent_num):\n",
    "        for row in self.board:\n",
    "            if np.array_equal(row, agent_num * np.ones((3,))):\n",
    "                return True\n",
    "        for col in self.board.T:\n",
    "            if np.array_equal(col, agent_num * np.ones((3,))):\n",
    "                return True\n",
    "        diag = np.diag(self.board)\n",
    "        if np.array_equal(diag, agent_num * np.ones((3,))):\n",
    "            return True\n",
    "        diag = np.diag(np.fliplr(self.board))\n",
    "        if np.array_equal(diag, agent_num * np.ones((3,))):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def env_cleanup(self):\n",
    "        pass\n",
    "    \n",
    "    def env_message(self, message):\n",
    "        if message == 0:  # return available indices mask\n",
    "            return self.get_mask()\n",
    "            \n",
    "    def get_mask(self):\n",
    "        rows, cols = np.where(self.board == 0)\n",
    "        indices = rows * 3 + cols\n",
    "        mask = np.zeros((9,))\n",
    "        mask[indices] = 1\n",
    "        return mask\n",
    "    \n",
    "    def transform_index(self, index):\n",
    "        return index // 3, index % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToeAgent(BaseAgent):\n",
    "    def agent_init(self, agent_init_info):\n",
    "        self.discount = agent_init_info[\"discount\"]        \n",
    "        self.network = agent_init_info[\"network\"]\n",
    "        self.optimizer = agent_init_info[\"optimizer\"]\n",
    "        self.tau = agent_init_info[\"tau\"]\n",
    "        self.num_actions = agent_init_info[\"num_actions\"]\n",
    "        \n",
    "        self.rand_generator = self.network.rand_generator\n",
    "        \n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "\n",
    "    def policy(self, state, mask):\n",
    "        action_values = self.network.get_action_values(state)\n",
    "        probs = softmax(action_values, self.tau) \n",
    "        probs *= mask\n",
    "        probs /= probs.sum()\n",
    "        action = self.rand_generator.choice(self.num_actions, p=probs.squeeze())\n",
    "        return action\n",
    "\n",
    "    def agent_start(self, state, mask):\n",
    "        self.last_state = state\n",
    "        self.last_action = self.policy(self.last_state, mask)\n",
    "        return self.last_action        \n",
    "\n",
    "    def agent_step(self, reward, state, mask):\n",
    "        # SARSA\n",
    "        action = self.policy(state, mask)\n",
    "        self.network.get_action_values(state)\n",
    "        delta = reward + self.discount * self.network.get_action_values(state)[action] - \\\n",
    "                    self.network.get_action_values(self.last_state)[self.last_action]        \n",
    "        delta_mat = np.zeros((1,self.num_actions))\n",
    "        delta_mat[0, self.last_action] = delta\n",
    "        \n",
    "        grads = self.network.get_gradients(self.last_state, delta_mat)\n",
    "        self.optimizer.update_weights(self.network.get_weights(), grads)\n",
    "        \n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "        return action\n",
    "    \n",
    "    def agent_end(self, reward):\n",
    "        # SARSA\n",
    "        delta = reward - self.network.get_action_values(self.last_state)[self.last_action]        \n",
    "        delta_mat = np.zeros((1,self.num_actions))\n",
    "        delta_mat[0, self.last_action] = delta\n",
    "        \n",
    "        grads = self.network.get_gradients(self.last_state, delta_mat)\n",
    "        self.optimizer.update_weights(self.network.get_weights(), grads)\n",
    "        \n",
    "    def agent_message(self, message):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function approximator - a Feed-Forward NN \n",
    "layers1 = [9, 8, 9]\n",
    "layers2 = [9, 8, 9]\n",
    "nn1 = SimpleNN({\"layer_sizes\": layers1, \"seed\": 11})  # relu activations\n",
    "nn2 = SimpleNN({\"layer_sizes\": layers2, \"seed\": 2})  # relu activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48119347, -0.09126427, -0.03597601, -0.74359997, -0.04713915,\n",
       "        -0.05463695,  0.29797435,  0.23867763],\n",
       "       [ 0.11581143, -0.37073372, -0.54940611, -0.16799385,  0.18438121,\n",
       "         0.23976875, -0.26034616, -0.59885615],\n",
       "       [ 0.20266963,  0.5546932 , -0.05650711, -0.00287255,  0.64136414,\n",
       "         0.30530795,  0.25047701, -0.056715  ],\n",
       "       [ 0.1733056 ,  0.02889733,  0.73468766, -0.22735942,  0.16486643,\n",
       "        -0.09990757, -0.42657757, -0.39814628],\n",
       "       [-0.05109813, -0.13408972,  0.08107421, -0.03961176,  0.12662741,\n",
       "         0.66069023, -0.46246177,  0.5243487 ],\n",
       "       [-0.06525654, -0.43240221, -0.05581642, -0.10379415,  0.4444832 ,\n",
       "        -0.41503686, -0.15205646,  0.34152577],\n",
       "       [-0.46322043, -0.42340593,  0.30951677, -0.05482101,  0.30624341,\n",
       "         0.21540568,  0.54700046, -0.14072125],\n",
       "       [ 0.33256752, -0.28888757,  0.20990056,  0.11341743, -0.39186801,\n",
       "         0.40653596,  0.2342704 , -0.07584295],\n",
       "       [ 0.59320063, -0.27933386,  0.0659717 ,  0.58217301,  0.25358862,\n",
       "        -0.12606747,  0.08740617,  0.0743722 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.get_weights()[0][\"W\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer - ADAM (Momentum + RMSProp)\n",
    "optimizer_info = { \"step_size\": .1,\n",
    "                  \"beta_m\": 0.99,\n",
    "                  \"beta_v\": 0.999,\n",
    "                  \"epsilon\": 0.0001 }\n",
    "optimizer1 = Adam(layers1, optimizer_info)\n",
    "optimizer2 = Adam(layers2, optimizer_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(runs, nns, optimizers):\n",
    "    rlglue = RLGlue(TicTacToeEvnironment, TicTacToeAgent, TicTacToeAgent)\n",
    "    rewards = np.zeros((runs, 2))\n",
    "    starts = np.zeros((runs, 1))\n",
    "    final_states = np.zeros((runs, 9))\n",
    "    agent1_info = {\"discount\": 1, \"network\": nns[0], \"optimizer\": optimizers[0], \"tau\": 1, \"num_actions\": 9}\n",
    "    agent2_info = {\"discount\": 1, \"network\": nns[1], \"optimizer\": optimizers[1], \"tau\": 1, \"num_actions\": 9}\n",
    "    env_info = {}\n",
    "    rlglue.rl_init(agent1_info, agent2_info, env_info)\n",
    "\n",
    "    for i in tqdm(range(runs)):\n",
    "        rlglue.rl_episode(10)\n",
    "        rewards[i, :], starts[i, :], final_states[i, :] =  rlglue.rl_return()\n",
    "    return rlglue, rewards, starts, final_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15000/15000 [00:23<00:00, 650.20it/s]\n"
     ]
    }
   ],
   "source": [
    "rlg, rew, starts, states = experiment(runs, [nn1, nn2], [optimizer1, optimizer2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14555"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7939 + 6616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.]), array([ 1.,  0.,  0.,  1.,  1.,  0., -1., -1., -1.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts[-1], states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7939, 6616)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rew[:,0] > 0).sum() , (rew[:,1] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10755, 8123)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rew[:,0] > 0).sum() , (rew[:,1] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(rew[-100:,])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToeEvnironment()\n",
    "env.env_init()\n",
    "ret = env.env_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.19357819, -4.15218851, -1.89998162, -4.23414094, -1.97351013,\n",
       "       -4.2167366 , -1.72204512, -3.66648398, -1.72774215])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai = rlg.agents[1][\"agent\"]\n",
    "ai.network.get_action_values(ret[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.agent_start(ret[0], ret[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = env.env_step(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human (aka - me) will play 0, top-left\n",
    "ret = env.env_step(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = ai.agent_step(-1, ret[1], ret[3])\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = env.env_step(-1, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I choose 1, top-middle\n",
    "ret = env.env_step(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = ai.agent_step(-1, ret[1], ret[3])\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = env.env_step(-1, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " array([[ 1.,  1.,  0., -1., -1., -1.,  0.,  0.,  0.]]),\n",
       " True,\n",
       " array([0., 0., 1., 0., 0., 0., 1., 1., 1.]))"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret  # AI wins :-) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = rlg.agents[-1][\"agent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, mask = env.env_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.47968785, -6.5683146 , -3.30616794,  0.10791578,  0.51350736,\n",
       "        0.38507136, -1.97239166, -5.88189067, -4.42064227])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.network.get_action_values(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = ai.agent_start(state, mask)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward, state, ter, mask = env.env_step(-1, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward, state, ter, mask = env.env_step(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = ai.agent_start(state, mask)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward, state, ter, mask = env.env_step(-1, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward, state, ter, mask = env.env_step(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = ai.agent_start(state, mask)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward, state, ter, mask = env.env_step(-1, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., -1., -1.,  1., -1.,  0.,  0.]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's say I somehow missed\n",
    "reward, state, ter, mask = env.env_step(1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = ai.agent_start(state, mask)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " array([[ 1.,  0., -1., -1., -1.,  1., -1.,  0.,  1.]]),\n",
       " True,\n",
       " array([0., 1., 0., 0., 0., 0., 0., 1., 0.]))"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI wins again\n",
    "env.env_step(-1, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save this agent\n",
    "fw = open('agent-2-network-weights', 'wb')\n",
    "pickle.dump(ai.network.weights, fw)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
